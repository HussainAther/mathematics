"Following the coin-flipping examples, suppose we flip the coin a 
total of N = 12 times and it comes up heads in z = 8 of those flips. 
Suppose we let a beta(θ; 100, 1) distribution describe the head-biased 
trick coin, and we let a beta(θ; 1, 100) distribution describe the tail-biased trick coin.

We add a posterior predictive check: Is the winning model actually a good model of the data? 
In other words, one model can be whoppingly better than the other, but that does not necessarily 
mean that the winning model is a good model; it might mean merely that the winning model is 
less bad than the losing model. 

One way to examine the veracity of the winning model is to simulate data sampled from the 
winning model and see if the simulated data “look like” the actual data. To simulate data 
generated by the winning model, we do the following: First, we will randomly generate a 
value of θ from the posterior distribution of the winning model. Second, using that value of θ, 
we will generate a sample of coin flips. Third, we will count the number of heads in the sample, 
as a summary of the sample. 

Finally, we determine whether the number of heads in a typical simulated sample is close to the 
number of heads in our actual sample. The program below carries out these steps. 
Study it, run it, and answer the questions that follow."

